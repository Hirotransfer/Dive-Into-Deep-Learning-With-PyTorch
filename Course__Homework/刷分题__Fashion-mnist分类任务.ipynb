{"cells":[{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8816A83B754C47FB8A38337404E7685C","mdEditEnable":false},"source":"# Fashion-mnist分类任务"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"9734212DC1E446B49A991D99FCBC3CF6","mdEditEnable":false},"source":"# Fashion-mnist\n\n[经典的MNIST数据集](http://yann.lecun.com/exdb/mnist/)包含了大量的手写数字。十几年来，来自机器学习、机器视觉、人工智能、深度学习领域的研究员们把这个数据集作为衡量算法的基准之一。你会在很多的会议，期刊的论文中发现这个数据集的身影。实际上，MNIST数据集已经成为算法作者的必测的数据集之一。有人曾调侃道：*\"如果一个算法在MNIST不work, 那么它就根本没法用；而如果它在MNIST上work, 它在其他数据上也可能不work！\"*\n \n\n`Fashion-MNIST`的目的是要成为MNIST数据集的一个直接替代品。作为算法作者，你不需要修改任何的代码，就可以直接使用这个数据集。`Fashion-MNIST`的图片大小，训练、测试样本数及类别数与经典MNIST**完全相同**。\n\n这个数据集的样子大致如下（每个类别占三行）：\n\n![](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n\n\n## 类别标注\n\n在Fashion-mnist数据集中，每个训练样本都按照以下类别进行了标注：\n\n| 标注编号 | 描述 |\n| --- | --- |\n| 0 | T-shirt/top（T恤）|\n| 1 | Trouser（裤子）|\n| 2 | Pullover（套衫）|\n| 3 | Dress（裙子）|\n| 4 | Coat（外套）|\n| 5 | Sandal（凉鞋）|\n| 6 | Shirt（汗衫）|\n| 7 | Sneaker（运动鞋）|\n| 8 | Bag（包）|\n| 9 | Ankle boot（踝靴）|\n\n\n## 任务描述\n\n\n`Fashion-MNIST`是一个替代[MNIST手写数字集](http://yann.lecun.com/exdb/mnist/)的图像数据集。 它是由Zalando（一家德国的时尚科技公司）旗下的[研究部门](https://research.zalando.com/)提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。60000/10000的训练测试数据划分，28x28的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且**不需要**改动任何的代码。\n\n\n本次任务需要针对`Fashion-MNIST`数据集，设计、搭建、训练机器学习模型，能够尽可能准确地分辨出测试数据地标签。"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D5AF613D69164304B1ECD1A0CDA570A5","mdEditEnable":false},"source":"## 文档说明 \n\n\n数据集文件分为训练集和测试集部分，对应文件如下：\n\n- 训练数据：`train-images-idx3-ubyte.gz` \n- 训练标签：`train-labels-idx1-ubyte.gz`\n- 测试数据：`t10k-images-idx3-ubyte.gz`\n"},{"cell_type":"markdown","metadata":{"id":"CBDF0F702333469D8FA63476FDC4B4C5","jupyter":{},"mdEditEnable":false,"slideshow":{"slide_type":"slide"},"tags":[]},"source":"## 参考文献\n\n[1] Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n\n[2] https://github.com/zalandoresearch/fashion-mnist/"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"2A9E86C99B314A4086532929EA34375D","mdEditEnable":false},"source":"# 评估说明\n\n## 评价指标\n\n本次任务采用 [ACC（Accuracy)](https://baike.baidu.com/item/%E5%87%86%E7%A1%AE%E7%8E%87) 作为模型的评价标准。\n\n## 在线评估\n\n评估函数首先会验证选手提交的预测结果文件是否符合要求，主要验证了以下要求:\n\n1. 提交的预测文件是否存在重复ID\n2. 提交的预测文件ID是否与测试集文件ID不匹配\n\n通过验证后的文件会用以ACC为测评指标的函数进行计算评估。\n\n\n## 文件格式\n\n由于测评脚本已经统一，为保证脚本的顺利运行，在进行测评时，要求选手提交的`预测文件`拥有规范的字段名和字段格式，预测文件具体要求如下：\n\n| NO | 字段名称 | 数据类型 | 字段描述 |\n| -------- | -------- | -------- | -------- |\n| 1    | ID     | int    | ID序列     |\n| 2    | Prediction   | int     | 预测结果（类别值）   |\n\n正确格式的提交文件样例: `submission_random.csv`。\n\n## 基准算法\n\n本次任务采用不同的基准算法，获得模型的ACC如下：\n- 随机基准算法ACC：0.09440\n- 弱基准算法ACC：0.90452\n\n在评估时，以弱基准算法的ACC作为达标线。"},{"cell_type":"markdown","metadata":{"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"2A76EFAE8ACC41889389AB965120DB92","mdEditEnable":false},"source":"## 终审评估\n\n本次任务的终审评估将挑选在评分指标位于前10名的同学进行项目报告撰写，以描述模型、算法及实验等相关内容和结果，报告排版要求届时发布。\n\n除此以外，为保证竞赛的公平性，进入终审评估的同学需要提交项目代码，由助教进行模型的有效性验证。\n\n如发现实验结果有较大差异，或者模型无法复现等问题，组委会将取消营员本次14天陪你挑战《动手学深度学习》的结营资格，并且进行公示。"},{"metadata":{"id":"60FD932178F64A9E9F7C8DAB0FA11322","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 任务说明"},{"metadata":{"id":"4AA0FE2F64264A9D902CF0B430DCB30C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"> 针对`Fashion-MNIST`数据集，设计、搭建、训练机器学习模型，能够尽可能准确地分辨出测试数据集标签。\n\n> 数据集文件分为训练集和测试集部分，对应文件如下：\n\n>- 训练数据：`train-images-idx3-ubyte.gz` \n- 训练标签：`train-labels-idx1-ubyte.gz`\n- 测试数据：`t10k-images-idx3-ubyte.gz`"},{"metadata":{"id":"FB2EDF250F4B4089A82409CEA66D3DC2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 代码实现"},{"metadata":{"id":"6E09573C342042A88D615A56C8205B17","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 导入必需包\nimport os\nimport sys\nimport time\nimport math\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms","execution_count":1},{"metadata":{"id":"A7E1AED9EE55432484C830F486C63836","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义全剧平均池化类：普通的平均池化的窗口形状 --> Input：(H, W)\nclass GlobalAvgPool2d(nn.Module):\n    \"\"\"\n    全局平均池化层\n    可通过将普通的平均池化的窗口形状设置成输入的高和宽实现\n    \"\"\"\n    def __init__(self):\n        super(GlobalAvgPool2d, self).__init__()\n    def forward(self, x):\n        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n\n# 定义展平类\nclass FlattenLayer(torch.nn.Module):\n    def __init__(self):\n        super(FlattenLayer, self).__init__()\n    def forward(self, x): # x shape: （N, C, H, W）\n        return x.view(x.shape[0], -1)\n\n# 定义残差类（使用1*1卷积层来修改通道数）\nclass Residual(nn.Module): \n    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n        \"\"\"\n            use_1×1conv: 是否使用额外的1x1卷积层来修改通道数\n            stride: 卷积层的步幅\n        \"\"\"\n        super(Residual, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm2d(out_channels) # 批归一化\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, X):\n        Y = F.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        if self.conv3:\n            X = self.conv3(X)\n        return F.relu(Y + X)","execution_count":2},{"metadata":{"id":"86155A048CEC4530B6E5662254809CF1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义加载数据集函数\ndef load_data_fashion_mnist(batch_size, root='/home/kesci/work/FashionMNIST1045', use_normalize=False, mean=None, std=None):\n    \"\"\"下载数据集并将其加载进内存\"\"\"\n\n    if use_normalize: # 对输入进行归一化操作\n        normalize = transforms.Normalize(mean=[mean], std=[std])\n        # 进行数据增强：RandomCrop，RandomHorizontalFlip\n        train_augs = transforms.Compose([transforms.RandomCrop(28, padding=2),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.ToTensor(), \n                    normalize])\n        test_augs = transforms.Compose([transforms.ToTensor(), normalize])\n    else:\n        train_augs = transforms.Compose([transforms.ToTensor()])\n        test_augs = transforms.Compose([transforms.ToTensor()])\n    \n    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=train_augs)\n    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=test_augs)\n    if sys.platform.startswith('win'):\n        num_workers = 0  # 0 表示不用额外的进程来加速读取数据\n    else:\n        num_workers = 4  # 通过参数num_workers来设置进程读取数据（使用多进程来加速数据读取）\n    # DataLoader：允许使用多进程来加速数据读取\n    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    return train_iter, test_iter","execution_count":3},{"metadata":{"id":"5ADE6481310C40458D7672A1A850ABD1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----------------打印网络结构----------------\nSequential(\n  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (resnet_block1): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (resnet_block2): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (resnet_block3): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (resnet_block4): Sequential(\n    (0): Residual(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Residual(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (global_avg_pool): GlobalAvgPool2d()\n  (fc): Sequential(\n    (0): FlattenLayer()\n    (1): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n","name":"stdout"}],"source":"# 定义残差块函数\ndef resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n    '''\n    resnet\n    resnet使用步长为2（stride = 2）的卷积来替代pooling的作用！！！\n    resnet block\n    num_residuals: 当前block包含多少个残差块\n    first_block: 是否为第一个block\n    一个resnet block由num_residuals个残差块组成\n    其中第一个残差块起到了通道数的转换和pooling的作用\n    后面的若干残差块就是完成正常的特征提取\n    '''\n    if first_block:\n        assert in_channels == out_channels # 第一个模块的输出通道数同输入通道数一致\n    blk = []\n    for i in range(num_residuals):\n        if i == 0 and not first_block:\n            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n        else:\n            blk.append(Residual(out_channels, out_channels))\n    return nn.Sequential(*blk)\n\n# 定义resnet模型结构\n# resnet使用步长为2的卷积来替代pooling的作用！！！\nnet = nn.Sequential(\n        nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),   # 缩小感受野, 缩小通道数\n        nn.BatchNorm2d(32),\n        nn.ReLU())\n        #nn.ReLU(),\n        #nn.MaxPool2d(kernel_size=2, stride=2))   # 去掉maxpool缩小感受野\n\n# 追加连续4个block\nnet.add_module(\"resnet_block1\", resnet_block(32, 32, 2, first_block=True))   # channel统一减半\nnet.add_module(\"resnet_block2\", resnet_block(32, 64, 2))\nnet.add_module(\"resnet_block3\", resnet_block(64, 128, 2))\nnet.add_module(\"resnet_block4\", resnet_block(128, 256, 2))\n# 全局平均池化\nnet.add_module(\"global_avg_pool\", GlobalAvgPool2d()) \n# 全连接层\nnet.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(256, 10)))\n\nprint('----------------打印网络结构----------------')\nprint(net)","execution_count":4},{"metadata":{"id":"2E855C60BD17475497E17BBD1513B552","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"打印 1*1*28*28 输入经过每个模块后的shape\n0  output shape:\t torch.Size([1, 32, 28, 28])\n1  output shape:\t torch.Size([1, 32, 28, 28])\n2  output shape:\t torch.Size([1, 32, 28, 28])\nresnet_block1  output shape:\t torch.Size([1, 32, 28, 28])\nresnet_block2  output shape:\t torch.Size([1, 64, 14, 14])\nresnet_block3  output shape:\t torch.Size([1, 128, 7, 7])\nresnet_block4  output shape:\t torch.Size([1, 256, 4, 4])\nglobal_avg_pool  output shape:\t torch.Size([1, 256, 1, 1])\nfc  output shape:\t torch.Size([1, 10])\n","name":"stdout"}],"source":"print('打印 1*1*28*28 输入经过每个模块后的shape')\nX = torch.rand((1, 1, 28, 28))\nfor name, layer in net.named_children():\n    X = layer(X)\n    print(name, ' output shape:\\t', X.shape)","execution_count":5},{"metadata":{"id":"4F84B6961D3142CF840030ADE6A8AECC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----------------计算数据集的均值和标准差----------------\n----------------打印整个数据集的像素均值:0.286041207221936----------------\n----------------打印整个数据集的像素标准差:0.35289938988137576----------------\n","name":"stdout"}],"source":"print('----------------计算数据集的均值和标准差----------------')\nbatch_size = 64  \ntrain_iter, test_iter = load_data_fashion_mnist(batch_size, \n                        root='/home/kesci/work/FashionMNIST1045', use_normalize=False)\n# 求整个数据集的均值\ntemp_sum = 0\ncnt = 0\nfor X, y in train_iter:\n    if y.shape[0] != batch_size:\n        break   # 最后一个batch不足batch_size，忽略\n    channel_mean = torch.mean(X, dim=(0,2,3))  # 按channel求均值(不过这里只有1个channel)\n    cnt += 1   # cnt记录的是batch的个数，不是图像\n    temp_sum += channel_mean[0].item()\ndataset_global_mean = temp_sum / cnt\nprint('----------------打印整个数据集的像素均值:{}----------------'.format(dataset_global_mean))\n# 求整个数据集的标准差\ncnt = 0\ntemp_sum = 0\nfor X, y in train_iter:\n    if y.shape[0] != batch_size:\n        break   # 最后一个batch不足batch_size,这里就忽略了\n    residual = (X - dataset_global_mean) ** 2\n    channel_var_mean = torch.mean(residual, dim=(0,2,3))  \n    cnt += 1   # cnt记录的是batch的个数，不是图像\n    temp_sum += math.sqrt(channel_var_mean[0].item())\ndataset_global_std = temp_sum / cnt\nprint('----------------打印整个数据集的像素标准差:{}----------------'.format(dataset_global_std))               ","execution_count":6},{"metadata":{"id":"BF72CC5DA8404D6D97E3BE1C56D6A027","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 重新获取应用了归一化的数据集迭代器\nbatch_size = 64  \ntrain_iter, test_iter = load_data_fashion_mnist(batch_size, root='/home/kesci/work/FashionMNIST1045', use_normalize=True,\n                        mean = dataset_global_mean, std = dataset_global_std)","execution_count":7},{"metadata":{"id":"3043589DD47B42D297E98C87CD2D015C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义评估准确率\ndef evaluate_accuracy(data_iter, net, device=None):\n    if device is None and isinstance(net, torch.nn.Module):\n        # 如果没指定device就使用net的device\n        device = list(net.parameters())[0].device\n    net.eval() \n    acc_sum, n = 0.0, 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n            n += y.shape[0]\n    net.train() # 改回训练模式\n    return acc_sum / n","execution_count":8},{"metadata":{"id":"F356189CE86C4085A44A6C9B3D0A75DD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 定义训练模型\ndef train_model(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n    net = net.to(device)\n    print(\"----------------training on----------------\", device)\n    loss = torch.nn.CrossEntropyLoss()\n    best_test_acc = 0\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n        for X, y in train_iter:\n            X = X.to(device)\n            y = y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.cpu().item()\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n            n += y.shape[0]\n            batch_count += 1\n        test_acc = evaluate_accuracy(test_iter, net)\n        print('epoch %d, loss %.4f, train acc %.4f, test acc %.4f, time %.1f sec'\n              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n        if test_acc > best_test_acc:\n            print('find best! save at best.pth') # model/\n            best_test_acc = test_acc\n            torch.save(net.state_dict(), 'best.pth') # model/\n            #utils.save_model({\n            #    'arch': args.model,\n            #    'state_dict': net.state_dict()\n            #}, 'saved-models/{}-run-{}.pth.tar'.format(args.model, run))","execution_count":9},{"metadata":{"id":"0E53AD5AE54144D89F7809B6B1900C10","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----------------******训练******----------------\n----------------training on---------------- cpu\nepoch 1, loss 0.5268, train acc 0.8025, test acc 0.8496, time 590.7 sec\nfind best! save at best.pth\nepoch 2, loss 0.3248, train acc 0.8821, test acc 0.8923, time 598.0 sec\nfind best! save at best.pth\nepoch 3, loss 0.2795, train acc 0.8965, test acc 0.9000, time 591.3 sec\nfind best! save at best.pth\nepoch 4, loss 0.2511, train acc 0.9076, test acc 0.9095, time 592.0 sec\nfind best! save at best.pth\nepoch 5, loss 0.2334, train acc 0.9150, test acc 0.9145, time 598.9 sec\nfind best! save at best.pth\nepoch 6, loss 0.2211, train acc 0.9183, test acc 0.9177, time 591.1 sec\nfind best! save at best.pth\nepoch 7, loss 0.2125, train acc 0.9215, test acc 0.9158, time 593.8 sec\nepoch 8, loss 0.2034, train acc 0.9258, test acc 0.9193, time 595.5 sec\nfind best! save at best.pth\nepoch 9, loss 0.1977, train acc 0.9278, test acc 0.9216, time 591.7 sec\nfind best! save at best.pth\nepoch 10, loss 0.1897, train acc 0.9306, test acc 0.9269, time 596.1 sec\nfind best! save at best.pth\n","name":"stdout"}],"source":"print('----------------******训练******----------------')\nlr, num_epochs = 0.01, 10\n# optimizer = optim.Adam(net.parameters(), lr=lr) Adam优化算法\n# 修改优化算法 （区分Adam与SGD的异同）\noptimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4) \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ntrain_model(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","execution_count":10},{"metadata":{"id":"E6CBA2EED3204F01BFD33D317C384F7B","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----------------加载最优模型----------------\n----------------******测试******----------------\n","name":"stdout"}],"source":"print('----------------加载最优模型----------------')\nnet.load_state_dict(torch.load('best.pth')) # model/\nnet = net.to(device)\n\nprint('----------------******测试******----------------')\nnet.eval() \nid = 0\npreds_list = []\nwith torch.no_grad():\n    for X, y in test_iter:\n        batch_pred = list(net(X.to(device)).argmax(dim=1).cpu().numpy())\n        for y_pred in batch_pred:\n            preds_list.append((id, y_pred))\n            id += 1","execution_count":11},{"metadata":{"id":"94DB575F43F740B18650DCB6B075E5A6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----------------Submission Result----------------\n","name":"stdout"}],"source":"print('----------------Submission Result----------------')\nwith open('submission.csv', 'w') as f:\n    f.write('ID,Prediction\\n')\n    for id, pred in preds_list:\n        f.write('{},{}\\n'.format(id, pred))","execution_count":12}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}